{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ceb1a6ac-77f4-41b0-8382-0bbb01552be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy: 2.0.2\n",
      "pandas: 2.2.3\n",
      "sklearn: 1.6.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np; print(\"numpy:\", np.__version__)\n",
    "import pandas as pd; print(\"pandas:\", pd.__version__)\n",
    "import sklearn; print(\"sklearn:\", sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf00daa9-dbbc-484c-aa06-621ac4d3f13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.perf_counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d78cc84-0b2a-4202-bfb2-3c556e40eb17",
   "metadata": {},
   "source": [
    "#### dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a148337-e6c2-40a0-abde-8708b8445fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 128) (10000,) (10000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import random\n",
    "import string\n",
    "\n",
    "X, y = make_classification(n_samples=10000, n_features=128, n_informative=10, n_redundant=60, n_repeated=0, n_classes=5, \n",
    "                           n_clusters_per_class=3, weights=None, flip_y=0.01, class_sep=0.7)\n",
    "groups = np.array([''.join(random.choices(string.ascii_letters + string.digits, k=10)) for _ in range(len(y))])\n",
    "print(X.shape, y.shape, groups.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18fc222-a96e-4d91-a7f6-286cd8bc61a7",
   "metadata": {},
   "source": [
    "### create X, y, groups (by subject id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c20b46a6-d349-456a-b2c4-7a7be9ce9e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def get_X_y_groups(X_fname, df_fname, y_column_name, group_column_name):\n",
    "\n",
    "    '''\n",
    "    read X (pretrained model embeddings)\n",
    "    '''\n",
    "    X = np.load(X_fname)\n",
    "\n",
    "    '''\n",
    "    read metadata sheet\n",
    "    '''\n",
    "    df = pd.read_csv(df_fname)\n",
    "    y = df[y_column_name].values\n",
    "    \n",
    "    '''\n",
    "    compile X, y, subject_groups\n",
    "    '''\n",
    "    groups_encoder = LabelEncoder().fit(df[group_column_name].tolist())\n",
    "    subject_groups = df.apply(lambda row: groups_encoder.transform([row[group_column_name]]), axis=1)\n",
    "    \n",
    "    assert len(X) == len(y) == len(subject_groups)\n",
    "\n",
    "    return X, y, subject_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11329f5-e0ce-40c2-913c-ef41f4af2024",
   "metadata": {},
   "source": [
    "### for a given probe_type/feature_type and model_patch_size, train new linear probes for all available model checkpoints "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2189dbb-1fcb-4bdd-b34d-c04129738fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['epoch_10',\n",
       " 'epoch_20',\n",
       " 'epoch_30',\n",
       " 'epoch_40',\n",
       " 'epoch_50',\n",
       " 'epoch_60',\n",
       " 'epoch_70',\n",
       " 'epoch_80',\n",
       " 'epoch_90',\n",
       " 'epoch_100']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.pipeline import multiclass_clf_pipeline_runner\n",
    "\n",
    "'''\n",
    "all common/global config across all linear probes\n",
    "'''\n",
    "\n",
    "feature_type = \"channel_region\"\n",
    "model_patch_size = \"1sec\"\n",
    "\n",
    "model_type = \"LogReg_L2_MultiClass\"\n",
    "cv_type = \"Simple_KFold\"\n",
    "cv_params = {\n",
    "     'cv_folds': {\"outer\": 10},\n",
    "     'n_jobs': {\"outer\": 1, \"model_fit\": 10},\n",
    "     'random_state': 2509843\n",
    "}\n",
    "\n",
    "model_checkpoints = [f\"epoch_{x}\" for x in range(10, 110, 10)]\n",
    "model_checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d34eeb4-2464-4826-ab4b-9b53fc96e0cd",
   "metadata": {},
   "source": [
    "### serial execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4029042c-9ce7-4be9-9fac-8bc40ddc0ad5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** ALL DATA USED FOR OUTER CV: (10000, 128) [0 1 2 3 4] [2000 1994 2000 2003 2003]\n",
      "Fold 0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 6:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 7:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 8:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 9:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 17\u001b[0m\n\u001b[1;32m     13\u001b[0m X, y \u001b[38;5;241m=\u001b[39m make_classification(n_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m, n_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, n_informative\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, n_redundant\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m60\u001b[39m, n_repeated\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, n_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, \n\u001b[1;32m     14\u001b[0m                            n_clusters_per_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, flip_y\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, class_sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m)\n\u001b[1;32m     15\u001b[0m groups \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(random\u001b[38;5;241m.\u001b[39mchoices(string\u001b[38;5;241m.\u001b[39mascii_letters \u001b[38;5;241m+\u001b[39m string\u001b[38;5;241m.\u001b[39mdigits, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(y))])\n\u001b[0;32m---> 17\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmulticlass_clf_pipeline_runner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m all_probes[checkpoint] \u001b[38;5;241m=\u001b[39m results[model_type]\n",
      "File \u001b[0;32m/mnt/Helium/neeraj/ssl_feature_probes/utils/pipeline.py:35\u001b[0m, in \u001b[0;36mmulticlass_clf_pipeline_runner\u001b[0;34m(X, y, groups, model_type, cv_type, cv_params)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03mcompute multi-class classification metrics\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     34\u001b[0m _, all_outer_fold_subject_groups, all_outer_fold_true_y, all_best_fit_pred_y_probs \u001b[38;5;241m=\u001b[39m full_cv_results\n\u001b[0;32m---> 35\u001b[0m model_metrics_across_folds \u001b[38;5;241m=\u001b[39m \u001b[43mget_multiclass_clf_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_outer_fold_true_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_best_fit_pred_y_probs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mall_outer_fold_subject_groups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m all_results \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     39\u001b[0m     model_type: {\n\u001b[1;32m     40\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcv_type\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_type,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     44\u001b[0m     }\n\u001b[1;32m     45\u001b[0m }\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m all_results\n",
      "File \u001b[0;32m/mnt/Helium/neeraj/ssl_feature_probes/utils/metrics.py:186\u001b[0m, in \u001b[0;36mget_multiclass_clf_metrics\u001b[0;34m(all_outer_fold_true_y, all_best_fit_pred_y_probs, all_outer_fold_subject_groups, cv_params, model_type)\u001b[0m\n\u001b[1;32m    183\u001b[0m model_metrics_across_folds \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    185\u001b[0m \u001b[38;5;66;03m# sequence = single-channel 10s epoch\u001b[39;00m\n\u001b[0;32m--> 186\u001b[0m model_metrics_across_folds[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msequence_level\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43m_compute_multiclass_clf_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_outer_fold_true_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_best_fit_pred_y_probs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m                                                             \u001b[49m\u001b[43mall_outer_fold_subject_groups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m                                                             \u001b[49m\u001b[43mmetric_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msequence_level\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m                                                             \u001b[49m\u001b[43mnum_outer_folds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcv_folds\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mouter\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m                                                            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metrics_type \u001b[38;5;129;01min\u001b[39;00m model_metrics_across_folds\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m --------------- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics_type\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ---------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/mnt/Helium/neeraj/ssl_feature_probes/utils/metrics.py:106\u001b[0m, in \u001b[0;36m_compute_multiclass_clf_metrics\u001b[0;34m(all_outer_fold_true_y, all_best_fit_pred_y_probs, all_outer_fold_subject_groups, metric_type, num_outer_folds)\u001b[0m\n\u001b[1;32m    104\u001b[0m acc \u001b[38;5;241m=\u001b[39m accuracy_score(all_true_y, all_pred_y_preds)\n\u001b[1;32m    105\u001b[0m bal_acc \u001b[38;5;241m=\u001b[39m balanced_accuracy_score(all_true_y, all_pred_y_preds)\n\u001b[0;32m--> 106\u001b[0m f1 \u001b[38;5;241m=\u001b[39m \u001b[43mf1_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_true_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_pred_y_preds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m model_metrics_across_folds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(acc)\n\u001b[1;32m    109\u001b[0m model_metrics_across_folds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbal_accs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(bal_acc)\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/sklearn/utils/_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    226\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1324\u001b[0m, in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m   1145\u001b[0m     {\n\u001b[1;32m   1146\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1172\u001b[0m ):\n\u001b[1;32m   1173\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the F1 score, also known as balanced F-score or F-measure.\u001b[39;00m\n\u001b[1;32m   1174\u001b[0m \n\u001b[1;32m   1175\u001b[0m \u001b[38;5;124;03m    The F1 score can be interpreted as a harmonic mean of the precision and\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;124;03m    array([0.66666667, 1.        , 0.66666667])\u001b[39;00m\n\u001b[1;32m   1323\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfbeta_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1326\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1333\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/sklearn/utils/_param_validation.py:189\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517\u001b[0m, in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1336\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m   1337\u001b[0m     {\n\u001b[1;32m   1338\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1365\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1366\u001b[0m ):\n\u001b[1;32m   1367\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the F-beta score.\u001b[39;00m\n\u001b[1;32m   1368\u001b[0m \n\u001b[1;32m   1369\u001b[0m \u001b[38;5;124;03m    The F-beta score is the weighted harmonic mean of precision and recall,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m \u001b[38;5;124;03m    0.12...\u001b[39;00m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1517\u001b[0m     _, _, f, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1518\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1519\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1523\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1524\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarn_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mf-score\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1525\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1527\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1528\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/sklearn/utils/_param_validation.py:189\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1830\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1661\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute precision, recall, F-measure and support for each class.\u001b[39;00m\n\u001b[1;32m   1662\u001b[0m \n\u001b[1;32m   1663\u001b[0m \u001b[38;5;124;03mThe precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1827\u001b[0m \u001b[38;5;124;03m array([2, 2, 2]))\u001b[39;00m\n\u001b[1;32m   1828\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1829\u001b[0m _check_zero_division(zero_division)\n\u001b[0;32m-> 1830\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43m_check_set_wise_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1832\u001b[0m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[1;32m   1833\u001b[0m samplewise \u001b[38;5;241m=\u001b[39m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1613\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1611\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1612\u001b[0m             average_options\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1613\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1614\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget is \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m but average=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Please \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1615\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoose another average setting, one of \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (y_type, average_options)\n\u001b[1;32m   1616\u001b[0m         )\n\u001b[1;32m   1617\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pos_label \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1618\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1619\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNote that pos_label (set to \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) is ignored when \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1620\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage != \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (got \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m). You may use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1623\u001b[0m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m   1624\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "all_probes = OrderedDict()\n",
    "\n",
    "for checkpoint in model_checkpoints:\n",
    "\n",
    "    # X, y, groups = get_X_y_groups(\n",
    "    #     X_fname=f\"{model_patch_size}_{checkpoint}.npy\",\n",
    "    #     df_fname=\"metadata.csv\",\n",
    "    #     y_column_name=feature_type,\n",
    "    #     group_column_name=\"subject_id\",\n",
    "    # )\n",
    "    \n",
    "    X, y = make_classification(n_samples=10000, n_features=128, n_informative=10, n_redundant=60, n_repeated=0, n_classes=5, \n",
    "                               n_clusters_per_class=3, weights=None, flip_y=0.01, class_sep=0.7)\n",
    "    groups = np.array([''.join(random.choices(string.ascii_letters + string.digits, k=10)) for _ in range(len(y))])\n",
    "        \n",
    "    results = multiclass_clf_pipeline_runner(X, y, groups, model_type, cv_type, cv_params)\n",
    "    all_probes[checkpoint] = results[model_type]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091edba3-f5e0-4a36-a051-2c803d8d4713",
   "metadata": {},
   "source": [
    "### FIXME: TODO: parallel execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554e15a5-2569-44de-958d-5805c8373dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...................."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc666d8-9545-41da-b40d-e67dc24579cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "date = \"5_13_25\"\n",
    "# with open(f\"{model_patch_size}_{feature_type}_probes_for_all_checkpoints_{date}.pkl\", 'wb') as f:\n",
    "#     pickle.dump(all_probes, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b393818-4ce1-49da-8ccb-1842639e3eef",
   "metadata": {},
   "source": [
    "### plot heldout test probe scores (y-axis) w/ stderr (from kfoldcv) for all model checkpoints (x-axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b981978-8f86-4dff-a39b-9900cb9f16d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "plt.rcParams['xtick.labelsize'] = 14\n",
    "plt.rcParams['ytick.labelsize'] = 14\n",
    "plt.rcParams['legend.fontsize'] = 11\n",
    "plt.rcParams['font.size'] = 14\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "_df_rows = []\n",
    "for key, item in all_probes.items():\n",
    "    # # print(key, item.keys())\n",
    "    all_mse = item[\"model_metrics_across_folds\"][\"sequence_level\"][\"mean_squared_errors\"]\n",
    "    all_mae = item[\"model_metrics_across_folds\"][\"sequence_level\"][\"mean_absolute_errors\"]\n",
    "    all_r2 = item[\"model_metrics_across_folds\"][\"sequence_level\"][\"r2_scores\"]\n",
    "    for (mse, mae, r2) in zip(all_mse, all_mae, all_r2):\n",
    "        tmp = {}\n",
    "        tmp['x'] = key\n",
    "        tmp['mse'] = mse\n",
    "        tmp['mae'] = mae\n",
    "        tmp['r2'] = r2\n",
    "        _df_rows.append(tmp)\n",
    "        \n",
    "plot_df = pd.DataFrame(_df_rows)\n",
    "\n",
    "sns.lineplot(\n",
    "    data=plot_df, x='x', y='mse', errorbar='sd', err_style=\"band\",\n",
    "    marker=\"o\", \n",
    "    label=f\"Patch size: {model_patch_size}\",\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "plt.xticks(rotation=20)\n",
    "plt.xlabel(\"Checkpoints\", fontsize=20)\n",
    "plt.ylabel(f\"{feature_type} Probe MSE (heldout set)\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7628cc-feb9-4a5c-9f39-1362aeba2d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.perf_counter()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Wall-clock time: {elapsed_time:.4f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
